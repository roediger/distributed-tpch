sqlContext.sql("DROP TABLE IF EXISTS default.lineitem")
sqlContext.sql("DROP TABLE IF EXISTS default.part")
sqlContext.sql("DROP TABLE IF EXISTS default.supplier")
sqlContext.sql("DROP TABLE IF EXISTS default.partsupp")
sqlContext.sql("DROP TABLE IF EXISTS default.nation")
sqlContext.sql("DROP TABLE IF EXISTS default.region")
sqlContext.sql("DROP TABLE IF EXISTS default.customer")
sqlContext.sql("DROP TABLE IF EXISTS default.orders")

sqlContext.sql("CREATE TABLE lineitem (L_ORDERKEY INT, L_PARTKEY INT, L_SUPPKEY INT, L_LINENUMBER INT, L_QUANTITY DOUBLE, L_EXTENDEDPRICE DOUBLE, L_DISCOUNT DOUBLE, L_TAX DOUBLE, L_RETURNFLAG STRING, L_LINESTATUS STRING, L_SHIPDATE STRING, L_COMMITDATE STRING, L_RECEIPTDATE STRING, L_SHIPINSTRUCT STRING, L_SHIPMODE STRING, L_COMMENT STRING) USING com.databricks.spark.csv OPTIONS (path '/tpch/100/lineitem', header 'false', delimiter '|')")
sqlContext.sql("CREATE TABLE orders (O_ORDERKEY INT, O_CUSTKEY INT, O_ORDERSTATUS STRING, O_TOTALPRICE DOUBLE, O_ORDERDATE STRING, O_ORDERPRIORITY STRING, O_CLERK STRING, O_SHIPPRIORITY INT, O_COMMENT STRING) USING com.databricks.spark.csv OPTIONS (path '/tpch/100/orders', header 'false', delimiter '|')")
sqlContext.sql("CREATE TABLE partsupp (PS_PARTKEY INT, PS_SUPPKEY INT, PS_AVAILQTY INT, PS_SUPPLYCOST DOUBLE, PS_COMMENT STRING) USING com.databricks.spark.csv OPTIONS (path '/tpch/100/partsupp', header 'false', delimiter '|')")
sqlContext.sql("CREATE TABLE part (P_PARTKEY INT, P_NAME STRING, P_MFGR STRING, P_BRAND STRING, P_TYPE STRING, P_SIZE INT, P_CONTAINER STRING, P_RETAILPRICE DOUBLE, P_COMMENT STRING) USING com.databricks.spark.csv OPTIONS (path '/tpch/100/part', header 'false', delimiter '|')")
sqlContext.sql("CREATE TABLE customer (C_CUSTKEY INT, C_NAME STRING, C_ADDRESS STRING, C_NATIONKEY INT, C_PHONE STRING, C_ACCTBAL DOUBLE, C_MKTSEGMENT STRING, C_COMMENT STRING) USING com.databricks.spark.csv OPTIONS (path '/tpch/100/customer', header 'false', delimiter '|')")
sqlContext.sql("CREATE TABLE supplier (S_SUPPKEY INT, S_NAME STRING, S_ADDRESS STRING, S_NATIONKEY INT, S_PHONE STRING, S_ACCTBAL DOUBLE, S_COMMENT STRING) USING com.databricks.spark.csv OPTIONS (path '/tpch/100/supplier', header 'false', delimiter '|')")
sqlContext.sql("CREATE TABLE nation (N_NATIONKEY INT, N_NAME STRING, N_REGIONKEY INT, N_COMMENT STRING) USING com.databricks.spark.csv OPTIONS (path '/tpch/100/nation', header 'false', delimiter '|')")
sqlContext.sql("CREATE TABLE region (R_REGIONKEY INT, R_NAME STRING, R_COMMENT STRING) USING com.databricks.spark.csv OPTIONS (path '/tpch/100/region', header 'false', delimiter '|')")

val lineitem = sqlContext.table("lineitem")
lineitem.cache()
lineitem.registerTempTable("lineitem")
sqlContext.sql("SELECT count(*) FROM lineitem").show()

val orders = sqlContext.table("orders")
orders.cache()
orders.registerTempTable("orders")
sqlContext.sql("SELECT count(*) FROM orders").show()

val partsupp = sqlContext.table("partsupp")
partsupp.cache()
partsupp.registerTempTable("partsupp")
sqlContext.sql("SELECT count(*) FROM partsupp").show()

val part = sqlContext.table("part")
part.cache()
part.registerTempTable("part")
sqlContext.sql("SELECT count(*) FROM part").show()

val customer = sqlContext.table("customer")
customer.cache()
customer.registerTempTable("customer")
sqlContext.sql("SELECT count(*) FROM customer").show()

val supplier = sqlContext.table("supplier")
supplier.cache()
supplier.registerTempTable("supplier")
sqlContext.sql("SELECT count(*) FROM supplier").show()

val nation = sqlContext.table("nation")
nation.cache()
nation.registerTempTable("nation")
sqlContext.sql("SELECT count(*) FROM nation").show()

val region = sqlContext.table("region")
region.cache()
region.registerTempTable("region")
sqlContext.sql("SELECT count(*) FROM region").show()
